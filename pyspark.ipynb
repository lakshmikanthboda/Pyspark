{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvJQlJIqZihy",
        "outputId": "9df80c3f-263b-4ec6-b815-4e984312bab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 KB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=b72abe642084497f368345da12a894bc4edd38a8344a9c91ee97b3a677121135\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark py4j"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nrcdAuQ1aCI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating DataFrame manually**"
      ],
      "metadata": {
        "id": "hBJDJqIle36X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('test').getOrCreate()"
      ],
      "metadata": {
        "id": "Ul20kbf-aCMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data=[(1,'lk'),(2,'ch')]\n",
        "\n",
        "df=spark.createDataFrame(data=data,schema=('id','name'))\n",
        "\n",
        "df.show()\n",
        "df.printSchema()\n",
        "\n",
        "# to change schema\n",
        "from pyspark.sql.types import *\n",
        "schema = StructType([StructField(name='id',dataType=IntegerType()),StructField(name='name',dataType=StringType())])\n",
        "df=spark.createDataFrame(data=data,schema=schema)\n",
        "\n",
        "df.show()\n",
        "df.printSchema()\n",
        "\n",
        "# we can make dataframe using a dic as well\n",
        "\n",
        "data=[{'id':1,'name':'lk'},{'id':2,'name':'ch'}]\n",
        "\n",
        "df=spark.createDataFrame(data=data)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yPlbj63aXOW",
        "outputId": "da4f0f7d-195e-4339-bffd-3ab68fc056a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+\n",
            "| id|name|\n",
            "+---+----+\n",
            "|  1|  lk|\n",
            "|  2|  ch|\n",
            "+---+----+\n",
            "\n",
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n",
            "+---+----+\n",
            "| id|name|\n",
            "+---+----+\n",
            "|  1|  lk|\n",
            "|  2|  ch|\n",
            "+---+----+\n",
            "\n",
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n",
            "+---+----+\n",
            "| id|name|\n",
            "+---+----+\n",
            "|  1|  lk|\n",
            "|  2|  ch|\n",
            "+---+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w1eyHoZKfEDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read CSV**"
      ],
      "metadata": {
        "id": "cOONBZjtfEcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read.csv(path='/content/sample_data/california_housing_test.csv',header=True)\n",
        "display(df)\n",
        "df.show(5)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "crobi0hsfI2n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "78681d18-a520-45c8-dc9b-fb884e1e71b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[longitude: string, latitude: string, housing_median_age: string, total_rooms: string, total_bedrooms: string, population: string, households: string, median_income: string, median_house_value: string]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population|households|median_income|median_house_value|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|-122.050000|37.370000|         27.000000|3885.000000|    661.000000|1537.000000|606.000000|     6.608500|     344700.000000|\n",
            "|-118.300000|34.260000|         43.000000|1510.000000|    310.000000| 809.000000|277.000000|     3.599000|     176500.000000|\n",
            "|-117.810000|33.780000|         27.000000|3589.000000|    507.000000|1484.000000|495.000000|     5.793400|     270500.000000|\n",
            "|-118.360000|33.820000|         28.000000|  67.000000|     15.000000|  49.000000| 11.000000|     6.135900|     330000.000000|\n",
            "|-119.670000|36.330000|         19.000000|1241.000000|    244.000000| 850.000000|237.000000|     2.937500|      81700.000000|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- longitude: string (nullable = true)\n",
            " |-- latitude: string (nullable = true)\n",
            " |-- housing_median_age: string (nullable = true)\n",
            " |-- total_rooms: string (nullable = true)\n",
            " |-- total_bedrooms: string (nullable = true)\n",
            " |-- population: string (nullable = true)\n",
            " |-- households: string (nullable = true)\n",
            " |-- median_income: string (nullable = true)\n",
            " |-- median_house_value: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OR**"
      ],
      "metadata": {
        "id": "0WdmKmhGi0yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read.format('csv').option(key='header',value=True).load(path='/content/sample_data/california_housing_test.csv')\n",
        "display(df)\n",
        "df.show(5)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "NZMWRLEpi47W",
        "outputId": "f76c3b72-3799-4caf-bc6c-5b6abd1cf2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[longitude: string, latitude: string, housing_median_age: string, total_rooms: string, total_bedrooms: string, population: string, households: string, median_income: string, median_house_value: string]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population|households|median_income|median_house_value|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|-122.050000|37.370000|         27.000000|3885.000000|    661.000000|1537.000000|606.000000|     6.608500|     344700.000000|\n",
            "|-118.300000|34.260000|         43.000000|1510.000000|    310.000000| 809.000000|277.000000|     3.599000|     176500.000000|\n",
            "|-117.810000|33.780000|         27.000000|3589.000000|    507.000000|1484.000000|495.000000|     5.793400|     270500.000000|\n",
            "|-118.360000|33.820000|         28.000000|  67.000000|     15.000000|  49.000000| 11.000000|     6.135900|     330000.000000|\n",
            "|-119.670000|36.330000|         19.000000|1241.000000|    244.000000| 850.000000|237.000000|     2.937500|      81700.000000|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- longitude: string (nullable = true)\n",
            " |-- latitude: string (nullable = true)\n",
            " |-- housing_median_age: string (nullable = true)\n",
            " |-- total_rooms: string (nullable = true)\n",
            " |-- total_bedrooms: string (nullable = true)\n",
            " |-- population: string (nullable = true)\n",
            " |-- households: string (nullable = true)\n",
            " |-- median_income: string (nullable = true)\n",
            " |-- median_house_value: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aNXpQYtDkJ2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write CSV**"
      ],
      "metadata": {
        "id": "ZhtGMmafyPcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(1,'lk'),(2,'ch')]\n",
        "\n",
        "df=spark.createDataFrame(data=data,schema=('id','name'))\n",
        "\n",
        "df.show()\n",
        "\n",
        "df.write.csv(path='/content/sample_data/test2',header=True,mode='overwrite')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45FMTEXRySIr",
        "outputId": "3f1e7450-4c36-4602-8367-3c3ee32569e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+\n",
            "| id|name|\n",
            "+---+----+\n",
            "|  1|  lk|\n",
            "|  2|  ch|\n",
            "+---+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read JSON**"
      ],
      "metadata": {
        "id": "dgQ7UcUhz_cV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read.json(path='/content/sample_data/anscombe.json')\n",
        "df.show()\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAcCZcrj0Dwj",
        "outputId": "beee656d-65d0-4b44-e81e-b68560e99f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-----+---------------+\n",
            "|Series|   X|    Y|_corrupt_record|\n",
            "+------+----+-----+---------------+\n",
            "|  null|null| null|              [|\n",
            "|     I|10.0| 8.04|           null|\n",
            "|     I| 8.0| 6.95|           null|\n",
            "|     I|13.0| 7.58|           null|\n",
            "|     I| 9.0| 8.81|           null|\n",
            "|     I|11.0| 8.33|           null|\n",
            "|     I|14.0| 9.96|           null|\n",
            "|     I| 6.0| 7.24|           null|\n",
            "|     I| 4.0| 4.26|           null|\n",
            "|     I|12.0|10.84|           null|\n",
            "|     I| 7.0| 4.81|           null|\n",
            "|     I| 5.0| 5.68|           null|\n",
            "|    II|10.0| 9.14|           null|\n",
            "|    II| 8.0| 8.14|           null|\n",
            "|    II|13.0| 8.74|           null|\n",
            "|    II| 9.0| 8.77|           null|\n",
            "|    II|11.0| 9.26|           null|\n",
            "|    II|14.0|  8.1|           null|\n",
            "|    II| 6.0| 6.13|           null|\n",
            "|    II| 4.0|  3.1|           null|\n",
            "+------+----+-----+---------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- Series: string (nullable = true)\n",
            " |-- X: double (nullable = true)\n",
            " |-- Y: double (nullable = true)\n",
            " |-- _corrupt_record: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write JSON**"
      ],
      "metadata": {
        "id": "ZHzRKHpn16PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(1,'lk'),(2,'ch')]\n",
        "\n",
        "df=spark.createDataFrame(data=data,schema=('id','name'))\n",
        "\n",
        "df.show()\n",
        "\n",
        "df.write.json(path='/content/sample_data/testjson',mode='overwrite')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvKf_ns519Z5",
        "outputId": "f9a116e4-468c-40d1-b2af-b46b79140362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+\n",
            "| id|name|\n",
            "+---+----+\n",
            "|  1|  lk|\n",
            "|  2|  ch|\n",
            "+---+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SHOW**"
      ],
      "metadata": {
        "id": "zrGHuTzm2sPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(1,'lk'),(2,'chhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh')]\n",
        "\n",
        "df=spark.createDataFrame(data=data,schema=('id','name'))\n",
        "\n",
        "df.show(1) # to show only one value\n",
        "df.show(vertical=True)\n",
        "df.show(truncate=False) # to get full text without .'s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy3d9fMx3qMt",
        "outputId": "c0e0eb30-8646-4fcb-df65-fc9f53637091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+\n",
            "| id|name|\n",
            "+---+----+\n",
            "|  1|  lk|\n",
            "+---+----+\n",
            "only showing top 1 row\n",
            "\n",
            "-RECORD 0--------------------\n",
            " id   | 1                    \n",
            " name | lk                   \n",
            "-RECORD 1--------------------\n",
            " id   | 2                    \n",
            " name | chhhhhhhhhhhhhhhh... \n",
            "\n",
            "+---+---------------------------------------------+\n",
            "|id |name                                         |\n",
            "+---+---------------------------------------------+\n",
            "|1  |lk                                           |\n",
            "|2  |chhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh|\n",
            "+---+---------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1FvnKPSi2siz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WithColumn()**"
      ],
      "metadata": {
        "id": "3VEr_BUM9iIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(1,'lk','50000'),(2,'ch','4000')]\n",
        "schema=['id','name','salary']\n",
        "\n",
        "df=spark.createDataFrame(data=data,schema=schema)\n",
        "df.show()\n",
        "df.printSchema()\n",
        "\n",
        "from pyspark.sql.functions import col,lit\n",
        "\n",
        "df2=df.withColumn(colName='Salary',col=col('salary').cast('Integer')) # change type of column\n",
        "df2.printSchema()\n",
        "\n",
        "df3=df2.withColumn(colName='Salary',col=col('salary')*2) # math on all values in a column\n",
        "df3.show()\n",
        "\n",
        "df4=df3.withColumn(colName='country',col=lit('India')) # adding new column with constant value\n",
        "df4.show()\n",
        "\n",
        "df5=df4.withColumn(colName='SalaryCopy',col=col('Salary')) # add new column with same data from another column\n",
        "df5.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OPhltv59mP8",
        "outputId": "dd6a3c96-caa4-4579-b7dd-6e47d25688c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+------+\n",
            "| id|name|salary|\n",
            "+---+----+------+\n",
            "|  1|  lk| 50000|\n",
            "|  2|  ch|  4000|\n",
            "+---+----+------+\n",
            "\n",
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- salary: string (nullable = true)\n",
            "\n",
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n",
            "+---+----+------+\n",
            "| id|name|Salary|\n",
            "+---+----+------+\n",
            "|  1|  lk|100000|\n",
            "|  2|  ch|  8000|\n",
            "+---+----+------+\n",
            "\n",
            "+---+----+------+-------+\n",
            "| id|name|Salary|country|\n",
            "+---+----+------+-------+\n",
            "|  1|  lk|100000|  India|\n",
            "|  2|  ch|  8000|  India|\n",
            "+---+----+------+-------+\n",
            "\n",
            "+---+----+------+-------+----------+\n",
            "| id|name|Salary|country|SalaryCopy|\n",
            "+---+----+------+-------+----------+\n",
            "|  1|  lk|100000|  India|    100000|\n",
            "|  2|  ch|  8000|  India|      8000|\n",
            "+---+----+------+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WithColumnRenamed()**"
      ],
      "metadata": {
        "id": "R7IiZs4TAbUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(1,'lk','50000'),(2,'ch','4000')]\n",
        "schema=['id','name','salary']\n",
        "\n",
        "df=spark.createDataFrame(data=data,schema=schema)\n",
        "df.show()\n",
        "\n",
        "df1=df.withColumnRenamed('salary','salaryNEW') # Update Column Name \n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R2t8jS5Akuy",
        "outputId": "54381d8d-6204-466a-f56d-252f70303a6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+------+\n",
            "| id|name|salary|\n",
            "+---+----+------+\n",
            "|  1|  lk| 50000|\n",
            "|  2|  ch|  4000|\n",
            "+---+----+------+\n",
            "\n",
            "+---+----+---------+\n",
            "| id|name|salaryNEW|\n",
            "+---+----+---------+\n",
            "|  1|  lk|    50000|\n",
            "|  2|  ch|     4000|\n",
            "+---+----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**StructType() & StryctFiled()**"
      ],
      "metadata": {
        "id": "0TyJs1SjuwjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=[(1,'lk',3000),(2,'ch',5000)]\n",
        "schema=['id','name','salary']\n",
        "\n",
        "df=spark.createDataFrame(data,schema)\n",
        "df.show()\n",
        "df.printSchema()\n",
        "\n",
        "from pyspark.sql.types import StructType,StructField,IntegerType,StringType\n",
        "\n",
        "st=StructType([StructField(name='id',dataType=IntegerType()),\\\n",
        "               StructField(name='name',dataType=StringType()),\\\n",
        "               StructField(name='salary',dataType=IntegerType())])\n",
        "df2=spark.createDataFrame(data,st)\n",
        "df2.show()\n",
        "df2.printSchema()\n",
        "\n",
        "scc=StructType([StructField(name='fiest',dataType=StringType()),StructField(name='second',dataType=StringType())])\n",
        "\n",
        "sc=StructType([StructField(name='id',dataType=IntegerType()),StructField(name='name',dataType=scc),StructField(name='salary',dataType=IntegerType())])\n",
        "\n",
        "data=[(1,('lk','b'),3000),(2,('ch','b'),5000)]\n",
        "df3=spark.createDataFrame(data=data,schema=sc)\n",
        "df3.show()\n",
        "df3.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-FchLflu6qM",
        "outputId": "13b8742c-e2c2-4b6e-9a00-51e631243901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----+------+\n",
            "| id|name|salary|\n",
            "+---+----+------+\n",
            "|  1|  lk|  3000|\n",
            "|  2|  ch|  5000|\n",
            "+---+----+------+\n",
            "\n",
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+---+----+------+\n",
            "| id|name|salary|\n",
            "+---+----+------+\n",
            "|  1|  lk|  3000|\n",
            "|  2|  ch|  5000|\n",
            "+---+----+------+\n",
            "\n",
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n",
            "+---+-------+------+\n",
            "| id|   name|salary|\n",
            "+---+-------+------+\n",
            "|  1|{lk, b}|  3000|\n",
            "|  2|{ch, b}|  5000|\n",
            "+---+-------+------+\n",
            "\n",
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- fiest: string (nullable = true)\n",
            " |    |-- second: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Array Type**"
      ],
      "metadata": {
        "id": "uQ8XMRNoyPEM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xBh4YUXb0su-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "42RZaffFwAQ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}